{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subject: Classical Data Analysis\n",
    "\n",
    "## Session 1 - Regression\n",
    "\n",
    "### Individual assignment 1\n",
    "\n",
    "Develop a regression analysis in Statmodels (with and without a constant) and SKLearn, based on the Iris sklearn dataset. This data sets consists of 3 different types of irises’ (Setosa, Versicolour, and Virginica) petal and sepal length.\n",
    "\n",
    "See here for more information on this dataset: https://en.wikipedia.org/wiki/Iris_flower_data_set \n",
    "\n",
    "Use the field “sepal width (cm)” as independent variable and the field “sepal length (cm)” as dependent variable.\n",
    "\n",
    "- Interpret and discuss the OLS Regression Results.\n",
    "- Commit scripts in your GitHub account. You should export your solution code (.ipynb notebook) and push it to your repository “ClassicalDataAnalysis”.\n",
    "\n",
    "The following are the tasks that should complete and synchronize with your repository “ClassicalDataAnalysis” until October 13. Please notice that none of these tasks is graded, however it’s important that you correctly understand and complete them in order to be sure that you won’t have problems with further assignments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression in Statsmodels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)',\n",
       " 'sepal width (cm)',\n",
       " 'petal length (cm)',\n",
       " 'petal width (cm)']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "iris.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris_y = iris.data[:, np.newaxis, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris_X = iris.data[:, np.newaxis, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression model with Statsmodels and without a constant:¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=False, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression(fit_intercept=False, normalize=False, copy_X=True, n_jobs=1)\n",
    "regr.fit(iris_X, iris_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      " [[ 1.87167934]]\n",
      "Mean squared error: 1.50\n",
      "Variance score: -1.20\n"
     ]
    }
   ],
   "source": [
    "iris_y_pred = regr.predict(iris_X)\n",
    "print('Coefficients: \\n', regr.coef_\n",
    "     )\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % mean_squared_error(iris_y, iris_y_pred))\n",
    "print('Variance score: %.2f' % r2_score(iris_y, iris_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAADuCAYAAAAOR30qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niJRgQSYiUuJ/lf75iXP8vRoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119ec59e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(iris_X, iris_y,  color='black')\n",
    "plt.plot(iris_X, iris_y_pred, color='blue', linewidth=3)\n",
    "\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/roman2006/anaconda/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5.2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>6.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>7.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>7.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>7.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>6.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                  5.1               3.5                1.4               0.2\n",
       "1                  4.9               3.0                1.4               0.2\n",
       "2                  4.7               3.2                1.3               0.2\n",
       "3                  4.6               3.1                1.5               0.2\n",
       "4                  5.0               3.6                1.4               0.2\n",
       "5                  5.4               3.9                1.7               0.4\n",
       "6                  4.6               3.4                1.4               0.3\n",
       "7                  5.0               3.4                1.5               0.2\n",
       "8                  4.4               2.9                1.4               0.2\n",
       "9                  4.9               3.1                1.5               0.1\n",
       "10                 5.4               3.7                1.5               0.2\n",
       "11                 4.8               3.4                1.6               0.2\n",
       "12                 4.8               3.0                1.4               0.1\n",
       "13                 4.3               3.0                1.1               0.1\n",
       "14                 5.8               4.0                1.2               0.2\n",
       "15                 5.7               4.4                1.5               0.4\n",
       "16                 5.4               3.9                1.3               0.4\n",
       "17                 5.1               3.5                1.4               0.3\n",
       "18                 5.7               3.8                1.7               0.3\n",
       "19                 5.1               3.8                1.5               0.3\n",
       "20                 5.4               3.4                1.7               0.2\n",
       "21                 5.1               3.7                1.5               0.4\n",
       "22                 4.6               3.6                1.0               0.2\n",
       "23                 5.1               3.3                1.7               0.5\n",
       "24                 4.8               3.4                1.9               0.2\n",
       "25                 5.0               3.0                1.6               0.2\n",
       "26                 5.0               3.4                1.6               0.4\n",
       "27                 5.2               3.5                1.5               0.2\n",
       "28                 5.2               3.4                1.4               0.2\n",
       "29                 4.7               3.2                1.6               0.2\n",
       "..                 ...               ...                ...               ...\n",
       "120                6.9               3.2                5.7               2.3\n",
       "121                5.6               2.8                4.9               2.0\n",
       "122                7.7               2.8                6.7               2.0\n",
       "123                6.3               2.7                4.9               1.8\n",
       "124                6.7               3.3                5.7               2.1\n",
       "125                7.2               3.2                6.0               1.8\n",
       "126                6.2               2.8                4.8               1.8\n",
       "127                6.1               3.0                4.9               1.8\n",
       "128                6.4               2.8                5.6               2.1\n",
       "129                7.2               3.0                5.8               1.6\n",
       "130                7.4               2.8                6.1               1.9\n",
       "131                7.9               3.8                6.4               2.0\n",
       "132                6.4               2.8                5.6               2.2\n",
       "133                6.3               2.8                5.1               1.5\n",
       "134                6.1               2.6                5.6               1.4\n",
       "135                7.7               3.0                6.1               2.3\n",
       "136                6.3               3.4                5.6               2.4\n",
       "137                6.4               3.1                5.5               1.8\n",
       "138                6.0               3.0                4.8               1.8\n",
       "139                6.9               3.1                5.4               2.1\n",
       "140                6.7               3.1                5.6               2.4\n",
       "141                6.9               3.1                5.1               2.3\n",
       "142                5.8               2.7                5.1               1.9\n",
       "143                6.8               3.2                5.9               2.3\n",
       "144                6.7               3.3                5.7               2.5\n",
       "145                6.7               3.0                5.2               2.3\n",
       "146                6.3               2.5                5.0               1.9\n",
       "147                6.5               3.0                5.2               2.0\n",
       "148                6.2               3.4                5.4               2.3\n",
       "149                5.9               3.0                5.1               1.8\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>sepal length (cm)</td> <th>  R-squared:         </th> <td>   0.957</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>        <th>  Adj. R-squared:    </th> <td>   0.957</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>   <th>  F-statistic:       </th> <td>   3316.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 16 Oct 2017</td>  <th>  Prob (F-statistic):</th> <td>1.04e-103</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>00:00:16</td>      <th>  Log-Likelihood:    </th> <td> -243.13</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   150</td>       <th>  AIC:               </th> <td>   488.3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   149</td>       <th>  BIC:               </th> <td>   491.3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>       <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>     <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sepal width (cm)</th> <td>    1.8717</td> <td>    0.033</td> <td>   57.585</td> <td> 0.000</td> <td>    1.807</td> <td>    1.936</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>16.884</td> <th>  Durbin-Watson:     </th> <td>   0.429</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>   7.669</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.336</td> <th>  Prob(JB):          </th> <td>  0.0216</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.120</td> <th>  Cond. No.          </th> <td>    1.00</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:      sepal length (cm)   R-squared:                       0.957\n",
       "Model:                            OLS   Adj. R-squared:                  0.957\n",
       "Method:                 Least Squares   F-statistic:                     3316.\n",
       "Date:                Mon, 16 Oct 2017   Prob (F-statistic):          1.04e-103\n",
       "Time:                        00:00:16   Log-Likelihood:                -243.13\n",
       "No. Observations:                 150   AIC:                             488.3\n",
       "Df Residuals:                     149   BIC:                             491.3\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "====================================================================================\n",
       "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------\n",
       "sepal width (cm)     1.8717      0.033     57.585      0.000       1.807       1.936\n",
       "==============================================================================\n",
       "Omnibus:                       16.884   Durbin-Watson:                   0.429\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):                7.669\n",
       "Skew:                          -0.336   Prob(JB):                       0.0216\n",
       "Kurtosis:                       2.120   Cond. No.                         1.00\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=df['sepal width (cm)']\n",
    "y= df['sepal length (cm)']\n",
    "model = sm.OLS(y, x).fit()\n",
    "predictions = model.predict(x)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting the Table "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing both methods we can see that actually the r-squared is pretty high, still seeing the graph I wpould beleive it to be a bad model, it is quite a surprise that it is actually good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression model with Statsmodels and with a constant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      " [[-0.20887029]]\n",
      "Mean squared error: 0.67\n",
      "Variance score: 0.01\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression(fit_intercept=True, normalize=False, copy_X=True, n_jobs=1)\n",
    "regr.fit(iris_X, iris_y)\n",
    "iris_y_pred = regr.predict(iris_X)\n",
    "print('Coefficients: \\n', regr.coef_\n",
    "     )\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % mean_squared_error(iris_y, iris_y_pred))\n",
    "print('Variance score: %.2f' % r2_score(iris_y, iris_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAADuCAYAAAAOR30qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1202d75f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(iris_X, iris_y,  color='black')\n",
    "plt.plot(iris_X, iris_y_pred, color='blue', linewidth=3)\n",
    "\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>sepal length (cm)</td> <th>  R-squared:         </th> <td>   0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>        <th>  Adj. R-squared:    </th> <td>   0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>   <th>  F-statistic:       </th> <td>   1.792</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 16 Oct 2017</td>  <th>  Prob (F-statistic):</th>  <td> 0.183</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>00:06:45</td>      <th>  Log-Likelihood:    </th> <td> -183.14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   150</td>       <th>  AIC:               </th> <td>   370.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   148</td>       <th>  BIC:               </th> <td>   376.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>     <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>            <td>    6.4812</td> <td>    0.481</td> <td>   13.466</td> <td> 0.000</td> <td>    5.530</td> <td>    7.432</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sepal width (cm)</th> <td>   -0.2089</td> <td>    0.156</td> <td>   -1.339</td> <td> 0.183</td> <td>   -0.517</td> <td>    0.099</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 4.455</td> <th>  Durbin-Watson:     </th> <td>   0.941</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.108</td> <th>  Jarque-Bera (JB):  </th> <td>   4.252</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.356</td> <th>  Prob(JB):          </th> <td>   0.119</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.585</td> <th>  Cond. No.          </th> <td>    24.3</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:      sepal length (cm)   R-squared:                       0.012\n",
       "Model:                            OLS   Adj. R-squared:                  0.005\n",
       "Method:                 Least Squares   F-statistic:                     1.792\n",
       "Date:                Mon, 16 Oct 2017   Prob (F-statistic):              0.183\n",
       "Time:                        00:06:45   Log-Likelihood:                -183.14\n",
       "No. Observations:                 150   AIC:                             370.3\n",
       "Df Residuals:                     148   BIC:                             376.3\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "====================================================================================\n",
       "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------\n",
       "const                6.4812      0.481     13.466      0.000       5.530       7.432\n",
       "sepal width (cm)    -0.2089      0.156     -1.339      0.183      -0.517       0.099\n",
       "==============================================================================\n",
       "Omnibus:                        4.455   Durbin-Watson:                   0.941\n",
       "Prob(Omnibus):                  0.108   Jarque-Bera (JB):                4.252\n",
       "Skew:                           0.356   Prob(JB):                        0.119\n",
       "Kurtosis:                       2.585   Cond. No.                         24.3\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x= df['sepal width (cm)']\n",
    "y= df['sepal length (cm)']\n",
    "x = sm.add_constant(x) \n",
    "model = sm.OLS(y, x).fit()\n",
    "predictions = model.predict(x)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting the Table "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a bad model, we can see that even though the mean squarred error is 0.67 the variance score is way to low so the points vary way too much, when done with statsmodel though, the R-squared is much lower, making it a completely unrelated model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression in SKLearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011961632834767699"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x= pd.DataFrame(df, columns=['sepal width (cm)'])\n",
    "y= pd.DataFrame(df, columns=['sepal length (cm)'])\n",
    "lm = linear_model.LinearRegression()\n",
    "model = lm.fit(x,y)\n",
    "lm.score(x,y) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.20887029]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.48122321])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.intercept_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
