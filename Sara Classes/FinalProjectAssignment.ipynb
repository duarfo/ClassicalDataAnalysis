{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project\n",
    "\n",
    "## Predict whether a mammogram mass is benign or malignant\n",
    "\n",
    "We'll be using the \"mammographic masses\" public dataset from the UCI repository (source: https://archive.ics.uci.edu/ml/datasets/Mammographic+Mass)\n",
    "\n",
    "This data contains 961 instances of masses detected in mammograms, and contains the following attributes:\n",
    "\n",
    "\n",
    "   1. BI-RADS assessment: 1 to 5 (ordinal)  \n",
    "   2. Age: patient's age in years (integer)\n",
    "   3. Shape: mass shape: round=1 oval=2 lobular=3 irregular=4 (nominal)\n",
    "   4. Margin: mass margin: circumscribed=1 microlobulated=2 obscured=3 ill-defined=4 spiculated=5 (nominal)\n",
    "   5. Density: mass density high=1 iso=2 low=3 fat-containing=4 (ordinal)\n",
    "   6. Severity: benign=0 or malignant=1 (binominal)\n",
    "   \n",
    "BI-RADS is an assesment of how confident the severity classification is; it is not a \"predictive\" attribute and so we will discard it. The age, shape, margin, and density attributes are the features that we will build our model with, and \"severity\" is the classification we will attempt to predict based on those attributes.\n",
    "\n",
    "Although \"shape\" and \"margin\" are nominal data types, which sklearn typically doesn't deal with well, they are close enough to ordinal that we shouldn't just discard them. The \"shape\" for example is ordered increasingly from round to irregular.\n",
    "\n",
    "A lot of unnecessary anguish and surgery arises from false positives arising from mammogram results. If we can build a better way to interpret them through supervised machine learning, it could improve a lot of lives.\n",
    "\n",
    "## Your assignment\n",
    "\n",
    "Apply several different supervised machine learning techniques to this data set, and see which one yields the highest accuracy as measured with K-Fold cross validation (K=10). Apply:\n",
    "\n",
    "* Decision tree\n",
    "* Random forest\n",
    "* KNN\n",
    "* Naive Bayes\n",
    "* SVM\n",
    "* Logistic Regression\n",
    "\n",
    "The data needs to be cleaned; many rows contain missing data, and there may be erroneous data identifiable as outliers as well.\n",
    "\n",
    "Remember some techniques such as SVM also require the input data to be normalized first.\n",
    "\n",
    "Many techniques also have \"hyperparameters\" that need to be tuned. Once you identify a promising approach, see if you can make it even better by tuning its hyperparameters.\n",
    "\n",
    "I was able to achieve over 80% accuracy - can you beat that?\n",
    "\n",
    "Below I've set up an outline of a notebook for this project, with some guidance and hints. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's begin: prepare your data\n",
    "\n",
    "Start by importing the mammographic_masses.data.txt file into a Pandas dataframe (hint: use read_csv) and take a look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>67</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>58</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1  2  3  4  5\n",
       "0  5  67  3  5  3  1\n",
       "1  4  43  1  1  ?  1\n",
       "2  5  58  4  5  3  1\n",
       "3  4  28  1  1  3  0\n",
       "4  5  74  1  5  ?  1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "db = pd.read_csv('mammographic_masses.data.txt',header=None)\n",
    "db.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "db.columns=['Bi-Rads','Age','Shape','Margin','Density','Severity']\n",
    "df=db.replace('?', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Bi-Rads',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you use the optional parmaters in read_csv to convert missing data (indicated by a ?) into NaN, and to add the appropriate column names (BI_RADS, age, shape, margin, density, and severity):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Shape</th>\n",
       "      <th>Margin</th>\n",
       "      <th>Density</th>\n",
       "      <th>Severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Age Shape Margin Density  Severity\n",
       "0  67     3      5       3         1\n",
       "1  43     1      1     NaN         1\n",
       "2  58     4      5       3         1\n",
       "3  28     1      1       3         0\n",
       "4  74     1      5     NaN         1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate whether the data needs cleaning; your model is only as good as the data it's given. Hint: use describe() on the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>961.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.463059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.498893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Severity\n",
       "count  961.000000\n",
       "mean     0.463059\n",
       "std      0.498893\n",
       "min      0.000000\n",
       "25%      0.000000\n",
       "50%      0.000000\n",
       "75%      1.000000\n",
       "max      1.000000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are quite a few missing values in the data set. Before we just drop every row that's missing data, let's make sure we don't bias our data in doing so. Does there appear to be any sort of correlation to what sort of data has missing fields? If there were, we'd have to try and go back and fill that data in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age          5\n",
       "Shape       31\n",
       "Margin      48\n",
       "Density     76\n",
       "Severity     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the missing data seems randomly distributed, go ahead and drop rows with missing data. Hint: use dropna()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Shape</th>\n",
       "      <th>Margin</th>\n",
       "      <th>Density</th>\n",
       "      <th>Severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>937</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>961 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Age  Shape  Margin  Density  Severity\n",
       "0    False  False   False    False     False\n",
       "1    False  False   False     True     False\n",
       "2    False  False   False    False     False\n",
       "3    False  False   False    False     False\n",
       "4    False  False   False     True     False\n",
       "5    False  False    True    False     False\n",
       "6    False   True    True    False     False\n",
       "7    False  False    True    False     False\n",
       "8    False  False   False    False     False\n",
       "9    False   True   False    False     False\n",
       "10   False  False   False    False     False\n",
       "11   False  False   False    False     False\n",
       "12   False  False    True    False     False\n",
       "13   False  False   False    False     False\n",
       "14   False  False   False    False     False\n",
       "15   False  False   False    False     False\n",
       "16   False  False   False    False     False\n",
       "17   False  False   False    False     False\n",
       "18   False  False   False    False     False\n",
       "19   False  False    True     True     False\n",
       "20   False   True    True    False     False\n",
       "21   False  False   False    False     False\n",
       "22   False  False    True     True     False\n",
       "23   False  False   False    False     False\n",
       "24   False  False   False    False     False\n",
       "25   False  False   False    False     False\n",
       "26   False  False   False     True     False\n",
       "27   False  False    True    False     False\n",
       "28   False  False   False    False     False\n",
       "29   False  False   False    False     False\n",
       "..     ...    ...     ...      ...       ...\n",
       "931  False  False   False    False     False\n",
       "932  False  False   False    False     False\n",
       "933  False  False   False    False     False\n",
       "934  False  False   False    False     False\n",
       "935  False  False   False    False     False\n",
       "936  False  False   False    False     False\n",
       "937  False  False   False    False     False\n",
       "938  False  False   False    False     False\n",
       "939  False  False   False    False     False\n",
       "940  False  False   False    False     False\n",
       "941  False  False   False    False     False\n",
       "942  False  False   False    False     False\n",
       "943  False  False   False    False     False\n",
       "944  False  False   False    False     False\n",
       "945  False  False   False    False     False\n",
       "946  False  False   False    False     False\n",
       "947  False  False   False    False     False\n",
       "948  False  False   False    False     False\n",
       "949  False  False   False    False     False\n",
       "950  False  False   False    False     False\n",
       "951  False  False   False    False     False\n",
       "952  False  False   False    False     False\n",
       "953  False  False   False    False     False\n",
       "954  False  False   False    False     False\n",
       "955  False  False   False    False     False\n",
       "956  False  False   False    False     False\n",
       "957  False  False   False    False     False\n",
       "958  False  False   False    False     False\n",
       "959  False  False   False    False     False\n",
       "960  False  False   False    False     False\n",
       "\n",
       "[961 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age         0\n",
       "Shape       0\n",
       "Margin      0\n",
       "Density     0\n",
       "Severity    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=df.dropna()\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py:2352: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    }
   ],
   "source": [
    "data[['Age','Shape','Margin','Density','Severity']]=data[['Age','Shape','Margin','Density','Severity']].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Shape</th>\n",
       "      <th>Margin</th>\n",
       "      <th>Density</th>\n",
       "      <th>Severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>831.000000</td>\n",
       "      <td>831.000000</td>\n",
       "      <td>831.000000</td>\n",
       "      <td>831.000000</td>\n",
       "      <td>831.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>55.777377</td>\n",
       "      <td>2.783394</td>\n",
       "      <td>2.814681</td>\n",
       "      <td>2.915764</td>\n",
       "      <td>0.484958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.663528</td>\n",
       "      <td>1.242331</td>\n",
       "      <td>1.566771</td>\n",
       "      <td>0.350737</td>\n",
       "      <td>0.500075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>46.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>57.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>66.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>96.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Age       Shape      Margin     Density    Severity\n",
       "count  831.000000  831.000000  831.000000  831.000000  831.000000\n",
       "mean    55.777377    2.783394    2.814681    2.915764    0.484958\n",
       "std     14.663528    1.242331    1.566771    0.350737    0.500075\n",
       "min     18.000000    1.000000    1.000000    1.000000    0.000000\n",
       "25%     46.000000    2.000000    1.000000    3.000000    0.000000\n",
       "50%     57.000000    3.000000    3.000000    3.000000    0.000000\n",
       "75%     66.000000    4.000000    4.000000    3.000000    1.000000\n",
       "max     96.000000    4.000000    5.000000    4.000000    1.000000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Next you'll need to convert the Pandas dataframes into numpy arrays that can be used by scikit_learn. Create an array that extracts only the feature data we want to work with (age, shape, margin, and density) and another array that contains the classes (severity). You'll also need an array of the feature name labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data[['Age','Shape','Margin','Density']]\n",
    "y=data['Severity']\n",
    "Names=['Age','Shape','Margin','Density']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of our models require the input data to be normalized, so go ahead and normalize the attribute data. Hint: use preprocessing.StandardScaler()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "import sklearn.preprocessing as pre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees\n",
    "\n",
    "Before moving to K-Fold cross validation and random forests, start by creating a single train/test split of our data. Set aside 75% for training, and 25% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, np.ravel(Y), test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create a DecisionTreeClassifier and fit it to your training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree = DecisionTreeClassifier()\n",
    "dtree.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measure the accuracy of the resulting decision tree model using your test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.73      0.71       101\n",
      "          1       0.74      0.70      0.72       107\n",
      "\n",
      "avg / total       0.72      0.72      0.72       208\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = dtree.predict(X_test)\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[74 27]\n",
      " [32 75]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.716346153846\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now instead of a single train/test split, use K-Fold cross validation to get a better measure of your model's accuracy (K=10). Hint: use model_selection.cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.71428571,  0.77380952,  0.71428571,  0.73493976,  0.78313253,\n",
       "        0.71084337,  0.72289157,  0.75903614,  0.75609756,  0.70731707])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(dtree, X, y, cv=10)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try a RandomForestClassifier instead. Does it perform better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.68      0.71       101\n",
      "          1       0.72      0.78      0.75       107\n",
      "\n",
      "avg / total       0.73      0.73      0.73       208\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators=150)\n",
    "rfc.fit(X_train, y_train)\n",
    "predictions = rfc.predict(X_test)\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[69 32]\n",
      " [24 83]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.730769230769\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM\n",
    "\n",
    "Next try using svm.SVC with a linear kernel. How does it compare to the decision tree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.67      0.76       101\n",
      "          1       0.74      0.90      0.81       107\n",
      "\n",
      "avg / total       0.80      0.79      0.79       208\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "SV = SVC(kernel='linear')\n",
    "SV.fit(X_train,y_train)\n",
    "predictions = SV.predict(X_test)\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[68 33]\n",
      " [11 96]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.788461538462\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 25 candidates, totalling 75 fits\n",
      "[CV] C=0.1, gamma=1, kernel=linear ...................................\n",
      "[CV]  C=0.1, gamma=1, kernel=linear, score=0.8221153846153846, total=   0.0s\n",
      "[CV] C=0.1, gamma=1, kernel=linear ...................................\n",
      "[CV]  C=0.1, gamma=1, kernel=linear, score=0.7980769230769231, total=   0.0s\n",
      "[CV] C=0.1, gamma=1, kernel=linear ...................................\n",
      "[CV]  C=0.1, gamma=1, kernel=linear, score=0.7681159420289855, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=linear .................................\n",
      "[CV]  C=0.1, gamma=0.1, kernel=linear, score=0.8221153846153846, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=linear .................................\n",
      "[CV]  C=0.1, gamma=0.1, kernel=linear, score=0.7980769230769231, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=linear .................................\n",
      "[CV]  C=0.1, gamma=0.1, kernel=linear, score=0.7681159420289855, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=linear ................................\n",
      "[CV]  C=0.1, gamma=0.01, kernel=linear, score=0.8221153846153846, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=linear ................................\n",
      "[CV]  C=0.1, gamma=0.01, kernel=linear, score=0.7980769230769231, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=linear ................................\n",
      "[CV]  C=0.1, gamma=0.01, kernel=linear, score=0.7681159420289855, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=linear ...............................\n",
      "[CV]  C=0.1, gamma=0.001, kernel=linear, score=0.8221153846153846, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=linear ...............................\n",
      "[CV]  C=0.1, gamma=0.001, kernel=linear, score=0.7980769230769231, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=linear ...............................\n",
      "[CV]  C=0.1, gamma=0.001, kernel=linear, score=0.7681159420289855, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=linear ..............................\n",
      "[CV]  C=0.1, gamma=0.0001, kernel=linear, score=0.8221153846153846, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=linear ..............................\n",
      "[CV]  C=0.1, gamma=0.0001, kernel=linear, score=0.7980769230769231, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=linear ..............................\n",
      "[CV]  C=0.1, gamma=0.0001, kernel=linear, score=0.7681159420289855, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=linear .....................................\n",
      "[CV]  C=1, gamma=1, kernel=linear, score=0.8221153846153846, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=linear .....................................\n",
      "[CV]  C=1, gamma=1, kernel=linear, score=0.8028846153846154, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=linear .....................................\n",
      "[CV]  C=1, gamma=1, kernel=linear, score=0.7681159420289855, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=linear ...................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=1, gamma=0.1, kernel=linear, score=0.8221153846153846, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=linear ...................................\n",
      "[CV]  C=1, gamma=0.1, kernel=linear, score=0.8028846153846154, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=linear ...................................\n",
      "[CV]  C=1, gamma=0.1, kernel=linear, score=0.7681159420289855, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=linear ..................................\n",
      "[CV]  C=1, gamma=0.01, kernel=linear, score=0.8221153846153846, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=linear ..................................\n",
      "[CV]  C=1, gamma=0.01, kernel=linear, score=0.8028846153846154, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=linear ..................................\n",
      "[CV]  C=1, gamma=0.01, kernel=linear, score=0.7681159420289855, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=linear .................................\n",
      "[CV]  C=1, gamma=0.001, kernel=linear, score=0.8221153846153846, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=linear .................................\n",
      "[CV]  C=1, gamma=0.001, kernel=linear, score=0.8028846153846154, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=linear .................................\n",
      "[CV]  C=1, gamma=0.001, kernel=linear, score=0.7681159420289855, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=linear ................................\n",
      "[CV]  C=1, gamma=0.0001, kernel=linear, score=0.8221153846153846, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=linear ................................\n",
      "[CV]  C=1, gamma=0.0001, kernel=linear, score=0.8028846153846154, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=linear ................................\n",
      "[CV]  C=1, gamma=0.0001, kernel=linear, score=0.7681159420289855, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=linear ....................................\n",
      "[CV]  C=10, gamma=1, kernel=linear, score=0.8221153846153846, total=   0.3s\n",
      "[CV] C=10, gamma=1, kernel=linear ....................................\n",
      "[CV]  C=10, gamma=1, kernel=linear, score=0.8028846153846154, total=   0.1s\n",
      "[CV] C=10, gamma=1, kernel=linear ....................................\n",
      "[CV]  C=10, gamma=1, kernel=linear, score=0.7681159420289855, total=   0.2s\n",
      "[CV] C=10, gamma=0.1, kernel=linear ..................................\n",
      "[CV]  C=10, gamma=0.1, kernel=linear, score=0.8221153846153846, total=   0.3s\n",
      "[CV] C=10, gamma=0.1, kernel=linear ..................................\n",
      "[CV]  C=10, gamma=0.1, kernel=linear, score=0.8028846153846154, total=   0.1s\n",
      "[CV] C=10, gamma=0.1, kernel=linear ..................................\n",
      "[CV]  C=10, gamma=0.1, kernel=linear, score=0.7681159420289855, total=   0.2s\n",
      "[CV] C=10, gamma=0.01, kernel=linear .................................\n",
      "[CV]  C=10, gamma=0.01, kernel=linear, score=0.8221153846153846, total=   0.3s\n",
      "[CV] C=10, gamma=0.01, kernel=linear .................................\n",
      "[CV]  C=10, gamma=0.01, kernel=linear, score=0.8028846153846154, total=   0.1s\n",
      "[CV] C=10, gamma=0.01, kernel=linear .................................\n",
      "[CV]  C=10, gamma=0.01, kernel=linear, score=0.7681159420289855, total=   0.2s\n",
      "[CV] C=10, gamma=0.001, kernel=linear ................................\n",
      "[CV]  C=10, gamma=0.001, kernel=linear, score=0.8221153846153846, total=   0.3s\n",
      "[CV] C=10, gamma=0.001, kernel=linear ................................\n",
      "[CV]  C=10, gamma=0.001, kernel=linear, score=0.8028846153846154, total=   0.1s\n",
      "[CV] C=10, gamma=0.001, kernel=linear ................................\n",
      "[CV]  C=10, gamma=0.001, kernel=linear, score=0.7681159420289855, total=   0.2s\n",
      "[CV] C=10, gamma=0.0001, kernel=linear ...............................\n",
      "[CV]  C=10, gamma=0.0001, kernel=linear, score=0.8221153846153846, total=   0.3s\n",
      "[CV] C=10, gamma=0.0001, kernel=linear ...............................\n",
      "[CV]  C=10, gamma=0.0001, kernel=linear, score=0.8028846153846154, total=   0.1s\n",
      "[CV] C=10, gamma=0.0001, kernel=linear ...............................\n",
      "[CV]  C=10, gamma=0.0001, kernel=linear, score=0.7681159420289855, total=   0.2s\n",
      "[CV] C=100, gamma=1, kernel=linear ...................................\n",
      "[CV]  C=100, gamma=1, kernel=linear, score=0.8221153846153846, total=   2.7s\n",
      "[CV] C=100, gamma=1, kernel=linear ...................................\n",
      "[CV]  C=100, gamma=1, kernel=linear, score=0.8028846153846154, total=   0.8s\n",
      "[CV] C=100, gamma=1, kernel=linear ...................................\n",
      "[CV]  C=100, gamma=1, kernel=linear, score=0.7681159420289855, total=   1.6s\n",
      "[CV] C=100, gamma=0.1, kernel=linear .................................\n",
      "[CV]  C=100, gamma=0.1, kernel=linear, score=0.8221153846153846, total=   2.6s\n",
      "[CV] C=100, gamma=0.1, kernel=linear .................................\n",
      "[CV]  C=100, gamma=0.1, kernel=linear, score=0.8028846153846154, total=   0.7s\n",
      "[CV] C=100, gamma=0.1, kernel=linear .................................\n",
      "[CV]  C=100, gamma=0.1, kernel=linear, score=0.7681159420289855, total=   1.6s\n",
      "[CV] C=100, gamma=0.01, kernel=linear ................................\n",
      "[CV]  C=100, gamma=0.01, kernel=linear, score=0.8221153846153846, total=   2.8s\n",
      "[CV] C=100, gamma=0.01, kernel=linear ................................\n",
      "[CV]  C=100, gamma=0.01, kernel=linear, score=0.8028846153846154, total=   0.8s\n",
      "[CV] C=100, gamma=0.01, kernel=linear ................................\n",
      "[CV]  C=100, gamma=0.01, kernel=linear, score=0.7681159420289855, total=   1.6s\n",
      "[CV] C=100, gamma=0.001, kernel=linear ...............................\n",
      "[CV]  C=100, gamma=0.001, kernel=linear, score=0.8221153846153846, total=   2.7s\n",
      "[CV] C=100, gamma=0.001, kernel=linear ...............................\n",
      "[CV]  C=100, gamma=0.001, kernel=linear, score=0.8028846153846154, total=   0.8s\n",
      "[CV] C=100, gamma=0.001, kernel=linear ...............................\n",
      "[CV]  C=100, gamma=0.001, kernel=linear, score=0.7681159420289855, total=   1.6s\n",
      "[CV] C=100, gamma=0.0001, kernel=linear ..............................\n",
      "[CV]  C=100, gamma=0.0001, kernel=linear, score=0.8221153846153846, total=   2.8s\n",
      "[CV] C=100, gamma=0.0001, kernel=linear ..............................\n",
      "[CV]  C=100, gamma=0.0001, kernel=linear, score=0.8028846153846154, total=   0.8s\n",
      "[CV] C=100, gamma=0.0001, kernel=linear ..............................\n",
      "[CV]  C=100, gamma=0.0001, kernel=linear, score=0.7681159420289855, total=   1.6s\n",
      "[CV] C=1000, gamma=1, kernel=linear ..................................\n",
      "[CV]  C=1000, gamma=1, kernel=linear, score=0.8221153846153846, total=  25.7s\n",
      "[CV] C=1000, gamma=1, kernel=linear ..................................\n",
      "[CV]  C=1000, gamma=1, kernel=linear, score=0.8028846153846154, total=   7.4s\n",
      "[CV] C=1000, gamma=1, kernel=linear ..................................\n",
      "[CV]  C=1000, gamma=1, kernel=linear, score=0.7681159420289855, total=  14.6s\n",
      "[CV] C=1000, gamma=0.1, kernel=linear ................................\n",
      "[CV]  C=1000, gamma=0.1, kernel=linear, score=0.8221153846153846, total=  25.7s\n",
      "[CV] C=1000, gamma=0.1, kernel=linear ................................\n",
      "[CV]  C=1000, gamma=0.1, kernel=linear, score=0.8028846153846154, total=   7.3s\n",
      "[CV] C=1000, gamma=0.1, kernel=linear ................................\n",
      "[CV]  C=1000, gamma=0.1, kernel=linear, score=0.7681159420289855, total=  14.0s\n",
      "[CV] C=1000, gamma=0.01, kernel=linear ...............................\n",
      "[CV]  C=1000, gamma=0.01, kernel=linear, score=0.8221153846153846, total=  24.3s\n",
      "[CV] C=1000, gamma=0.01, kernel=linear ...............................\n",
      "[CV]  C=1000, gamma=0.01, kernel=linear, score=0.8028846153846154, total=   7.1s\n",
      "[CV] C=1000, gamma=0.01, kernel=linear ...............................\n",
      "[CV]  C=1000, gamma=0.01, kernel=linear, score=0.7681159420289855, total=  13.8s\n",
      "[CV] C=1000, gamma=0.001, kernel=linear ..............................\n",
      "[CV]  C=1000, gamma=0.001, kernel=linear, score=0.8221153846153846, total=  24.3s\n",
      "[CV] C=1000, gamma=0.001, kernel=linear ..............................\n",
      "[CV]  C=1000, gamma=0.001, kernel=linear, score=0.8028846153846154, total=   7.1s\n",
      "[CV] C=1000, gamma=0.001, kernel=linear ..............................\n",
      "[CV]  C=1000, gamma=0.001, kernel=linear, score=0.7681159420289855, total=  13.9s\n",
      "[CV] C=1000, gamma=0.0001, kernel=linear .............................\n",
      "[CV]  C=1000, gamma=0.0001, kernel=linear, score=0.8221153846153846, total=  24.3s\n",
      "[CV] C=1000, gamma=0.0001, kernel=linear .............................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=1000, gamma=0.0001, kernel=linear, score=0.8028846153846154, total=   7.0s\n",
      "[CV] C=1000, gamma=0.0001, kernel=linear .............................\n",
      "[CV]  C=1000, gamma=0.0001, kernel=linear, score=0.7681159420289855, total=  13.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:  4.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.1, 1, 10, 100, 1000], 'gamma': [1, 0.1, 0.01, 0.001, 0.0001], 'kernel': ['linear']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=3)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [0.1,1, 10, 100, 1000], 'gamma': [1,0.1,0.01,0.001,0.0001], 'kernel': ['linear']}\n",
    "grid = GridSearchCV(SVC(),param_grid,refit=True,verbose=3)\n",
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'gamma': 1, 'kernel': 'linear'}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=1, kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_predictions = grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[68 33]\n",
      " [11 96]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,grid_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.67      0.76       101\n",
      "          1       0.74      0.90      0.81       107\n",
      "\n",
      "avg / total       0.80      0.79      0.79       208\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,grid_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.788461538462\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,grid_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN\n",
    "How about K-Nearest-Neighbors? Hint: use neighbors.KNeighborsClassifier - it's a lot easier than implementing KNN from scratch like we did earlier in the course. Start with a K of 10. K is an example of a hyperparameter - a parameter on the model itself which may need to be tuned for best results on your particular data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.70      0.74       101\n",
      "          1       0.74      0.80      0.77       107\n",
      "\n",
      "avg / total       0.76      0.75      0.75       208\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "KN= KNeighborsClassifier(n_neighbors=10)\n",
    "KN.fit(X_train,y_train)\n",
    "predictions = KN.predict(X_test)\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[71 30]\n",
      " [21 86]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.754807692308\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing K is tricky, so we can't discard KNN until we've tried different values of K. Write a for loop to run KNN with K values ranging from 1 to 50 and see if K makes a substantial difference. Make a note of the best performance you could get out of KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for K=1acurracy is:0.673076923077\n",
      "for K=2acurracy is:0.649038461538\n",
      "for K=3acurracy is:0.759615384615\n",
      "for K=4acurracy is:0.764423076923\n",
      "for K=5acurracy is:0.783653846154\n",
      "for K=6acurracy is:0.774038461538\n",
      "for K=7acurracy is:0.759615384615\n",
      "for K=8acurracy is:0.764423076923\n",
      "for K=9acurracy is:0.764423076923\n",
      "for K=10acurracy is:0.754807692308\n",
      "for K=11acurracy is:0.764423076923\n",
      "for K=12acurracy is:0.764423076923\n",
      "for K=13acurracy is:0.769230769231\n",
      "for K=14acurracy is:0.774038461538\n",
      "for K=15acurracy is:0.783653846154\n",
      "for K=16acurracy is:0.759615384615\n",
      "for K=17acurracy is:0.75\n",
      "for K=18acurracy is:0.754807692308\n",
      "for K=19acurracy is:0.745192307692\n",
      "for K=20acurracy is:0.735576923077\n",
      "for K=21acurracy is:0.745192307692\n",
      "for K=22acurracy is:0.740384615385\n",
      "for K=23acurracy is:0.730769230769\n",
      "for K=24acurracy is:0.721153846154\n",
      "for K=25acurracy is:0.735576923077\n",
      "for K=26acurracy is:0.730769230769\n",
      "for K=27acurracy is:0.730769230769\n",
      "for K=28acurracy is:0.721153846154\n",
      "for K=29acurracy is:0.730769230769\n",
      "for K=30acurracy is:0.730769230769\n",
      "for K=31acurracy is:0.740384615385\n",
      "for K=32acurracy is:0.735576923077\n",
      "for K=33acurracy is:0.730769230769\n",
      "for K=34acurracy is:0.740384615385\n",
      "for K=35acurracy is:0.754807692308\n",
      "for K=36acurracy is:0.735576923077\n",
      "for K=37acurracy is:0.745192307692\n",
      "for K=38acurracy is:0.75\n",
      "for K=39acurracy is:0.75\n",
      "for K=40acurracy is:0.740384615385\n",
      "for K=41acurracy is:0.740384615385\n",
      "for K=42acurracy is:0.725961538462\n",
      "for K=43acurracy is:0.725961538462\n",
      "for K=44acurracy is:0.716346153846\n",
      "for K=45acurracy is:0.721153846154\n",
      "for K=46acurracy is:0.711538461538\n",
      "for K=47acurracy is:0.711538461538\n",
      "for K=48acurracy is:0.706730769231\n",
      "for K=49acurracy is:0.701923076923\n",
      "for K=50acurracy is:0.706730769231\n"
     ]
    }
   ],
   "source": [
    "for number in range (1,51):\n",
    "    KN= KNeighborsClassifier(n_neighbors=number)\n",
    "    KN.fit(X_train,y_train)\n",
    "    predictions = KN.predict(X_test)\n",
    "    print('for K='+str(number)+'acurracy is:'+str((accuracy_score(y_test,predictions))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Acurracy for K=15 acurracy is:0.783653846154"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes\n",
    "\n",
    "Now try naive_bayes.MultinomialNB. How does its accuracy stack up? Hint: you'll need to use MinMaxScaler to get the features in the range MultinomialNB requires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.66      0.73       101\n",
      "          1       0.73      0.85      0.78       107\n",
      "\n",
      "avg / total       0.77      0.76      0.76       208\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "NB= MultinomialNB()\n",
    "NB.fit(X_train,y_train)\n",
    "predictions = NB.predict(X_test)\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[67 34]\n",
      " [16 91]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.759615384615\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revisiting SVM\n",
    "\n",
    "svm.SVC may perform differently with different kernels. The choice of kernel is an example of a \"hyperparamter.\" Try the rbf, sigmoid, and poly kernels and see what the best-performing kernel is. Do we have a new winner?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.759615384615\n"
     ]
    }
   ],
   "source": [
    "SV = SVC(kernel='rbf')\n",
    "SV.fit(X_train,y_train)\n",
    "predictions = SV.predict(X_test)\n",
    "print(accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.485576923077\n"
     ]
    }
   ],
   "source": [
    "SV = SVC(kernel='sigmoid')\n",
    "SV.fit(X_train,y_train)\n",
    "predictions = SV.predict(X_test)\n",
    "print(accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.754807692308\n"
     ]
    }
   ],
   "source": [
    "SV = SVC(kernel='poly')\n",
    "SV.fit(X_train,y_train)\n",
    "predictions = SV.predict(X_test)\n",
    "print(accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "We've tried all these fancy techniques, but fundamentally this is just a binary classification problem. Try Logisitic Regression, which is a simple way to tackling this sort of thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.783653846154\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train,y_train)\n",
    "predictions = logreg.predict(X_test)\n",
    "print(accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Do we have a winner?\n",
    "\n",
    "Which model, and which choice of hyperparameters, performed the best? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Amazingly withouth moving any parameters at all, the best performing model was Logistic Regression and KNN with just about 78%, with the modified parameters the best one was SVM with almost a 79%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
